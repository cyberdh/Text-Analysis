{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginning Text Preparation\n",
    "\n",
    "In order to perform text analysis, there are a few Python commands you should have up your sleeve. Some of the commands help get you set up and locate all of the files in your corpora. Other commands can be used throughout the programming process to check on your algorithm and make sure everything looks the way you think it should. Learning the following commands will give you a brief introduction to Python while also setting you up with a solid toolkit to begin programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading files from Github to Carbonate\n",
    "\n",
    "Since we will be using Carbonate as the example for our file paths and other elements in the scripts and Jupyter notebooks, many of you may want to save these files to Carbonate to make following along a bit easier. To do this you will need a Carbonate account if you do not already have one. Indiana University students, faculty, staff, and sponsored affiliates can request a Carbonate account. Steps on how to do so can be found [here](https://kb.iu.edu/d/aolp). Once you have your account, you'll want to be able to access the [Research Desktop (ReD)](https://kb.iu.edu/d/apum). You will also need to have access to ReD through the [thinlinc client](https://kb.iu.edu/d/aput). Once you have your account and can access it, you'll want to acquire the [Cyber DH Text-Analysis](https://github.com/cyberdh/Text-Analysis) GitHub repository and save it to Carbonate via Research Desktop. You can do this by opening the Firefox browser on ReD and going to [https://github.com/cyberdh/Text-Analysis](https://github.com/cyberdh/Text-Analysis) and clicking the green download button. Make sure to save it in your 'home' directory on ReD which should be your `/N/u/yourUserName/Carbonate` file path. Then extract the contents of the .zip file to the same 'home' folder just described in the previous sentence. Once you have done this you can also put a copy of the folder in your Box account.\n",
    "\n",
    "The nice thing about ReD is that it comes with a built in way for you to access your Box account so you can download the repository to Box and use the Text-Analysis notebooks and scripts on Carbonate and your own computer without having to use an SFTP client or some other means of moving files back and forth.\n",
    "\n",
    "To use Box on ReD go to Applications > Storage > Box setup and follow the instructions. You can also get help [here](https://kb.iu.edu/d/apxv#storage)\n",
    "\n",
    "Now that you have Carbonate, ReD, and Box up and running, lets make sure you can run the notebooks and scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Jupyter Notebook and Spyder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load Jupyter Notebook on ReD go to the top left corner of the desktop where its says \"Applications\" and go to Applications > Analytics > Jupyter Notebook and double click \"Jupyter Notebook\". It should load after a short wait. \n",
    "\n",
    "To load Spyder (which you will want to use with all our .py files) open your terminal and type `spyder` and hit return. There is a bit of a wait, but Spyder should open before a minute is up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opening a notebook or script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open a notebook (files ending in .ipynb) you will need to so do from Jupyter Notebook itself. When you first open Jupyter Notebook you will see a list of the folders in your 'home' directory (`/N/u/yourUserName/Carbonate`) on ReD. To get started with one of our notebooks navigate using those folders to where the notebook is stored. So if you wanted to open this notebook you would find `Text-Analysis-master` then open `Intro` then `Python` then `Py_notebooks` and finally click on `textPrep-Py.ipynb` and the notebook will open in another tab in your browser. To start a new notebook of your own look for the drop down menu labeled 'new' in the top right of the page when Jupyter Notebook first launches and choose Python 3. **DO NOT CHOOSE PYTHON 2.7** or these notebooks will not work. They are all written in Python 3.\n",
    "\n",
    "For running Python scripts in Spyder (files ending in .py) you also (like Jupyter Notebook) cannot double click a .py file and have Spyder launch. You need to launch Spyder as described above and then go to File > Open > and if you want to open our topTenPlainText-Py.py file you would start in your 'home' directory (same as above) go to `Text-Analysis-master` then open `Intro` then `Python` then `Py_notebooks` and finally click on `topTenPlainText-Py.py`. The script should open up in the Spyder application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running code in notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to run the code in the cells is to hit 'shift' + 'return' on your keyboard and this will run your code a cell at a time by running the highlighted cell and then moving to highlight the cell directly below it. If the cell is Markdown (which this current cell is) instead of code, it will read and interpret the Markdown in the cell and give you clean crisp text to read. If the cell is code, it will run the code and the produce any output (if the code in that cell has any) in the space just below the cell. If you wish to run the whole notebook at once, you can go to 'Cell' in the menu and choose the 'Run All' option. This will run every cell in the notebook beginnng with the top cell and ending with the bottom cell. This should be enough to get you started, so let's dig in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run CyberDH environment\n",
    "The code in the cell below points to a Python environment specificaly for use with the Python Jupyter Notebooks created by Cyberinfrastructure for Digital Humanities. It allows for the use of the different packages in our notebooks and their subsequent data sets. You will see this in all of our Python notebooks and scripts.\n",
    "\n",
    "##### Packages\n",
    "- **sys:** Provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter. It is always available.\n",
    "- **os:** Provides a portable way of using operating system dependent functionality.\n",
    "\n",
    "#### NOTE: This cell is only for use with Research Desktop. You will get an error if you try to run this cell on your personal device!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,\"/N/u/cyberdh/Carbonate/dhPyEnviron/lib/python3.6/site-packages\")\n",
    "os.environ[\"NLTK_DATA\"] = \"/N/u/cyberdh/Carbonate/dhPyEnviron/nltk_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beginning Text-Analysis with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Installing Packages\n",
    "While all the packages needed to run our notebooks are installed in our cyberdh Python environment on Carbonate, you may get adventurous and decide you want to change or adjust the notebooks, and, therefore, may need a package we don't have installed. To install a Python package on ReD you need to open your terminal using the icon on the ReD desktop. In the line type `pip3 install myDesiredPackage --user` and press enter. Replace the `myDesiredPackage` with the name of the package you want to install. The `--user` part of the code tells it to download it to your user profile and not system wide. Without the `--user` the system will not let you install the package as you do not have permission to install packages for everyone who uses ReD. Now, you should be able to use the functionality of your installed package along with the packages in our cyberdh Python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calling Packages\n",
    "Python uses various packages in order to expand on the capabilities of the language. This makes Python very flexible in it's uses and increases it's capabilities dramatically. Some packages have various modules within them, and sometimes you might want to call these modules within the package instead of the entire package. You can even call specific functions from the module if you plan on only using that function. This is what you see below. We call the nltk package, which stands for \"natural language tool kit.\" To call just the entire nltk package you would simply type `import nltk`. If we wanted to call nltk and the corpus module we would type `from nltk import corpus`. If we want to narrow it down to a function from the corpus module in nltk we type what you see below. The below code says from the `nltk` package go to the `.corpus` module and `import` the `PlaintextCorpusReader` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading your data file\n",
    "Now we need to point to the file or directory we will be using. \n",
    "\n",
    "The first variable, `homePath`, points to the home directory of whatever operating system you are on (Linux, osX, Windows). It does this using a function called `environ` from the `os` package we imported earlier. For Carbonate it automatically points to `/N/u/yourUserName/Carbonate` so you don't have to change the username in the file path constantly in our notebooks. The code `os.environ['HOME']` says that from the `os` package call the `environ` function to find the `['HOME']` file path. \n",
    "\n",
    "The second variable `corpusRoot` points to the directory our file is in. Again, we will be using functions from the `os` package. Here we use a function from a specific module from the `os` package to accomplish our goal. Our code `os.path.join` says that from the `os` package we need the `path` module and from that module we need the `join` function will join elements of a file path together. The elements of the file path it will join together are in the parantheses just after the function. So we are joining our `homePath` that we made above to the folder `'Text-Analysis-master'` which we then join to the folder `'data'`, which is finally joined to the `'shakespeareFolger'` folder. So the final file path created is '/N/u/myUserName/Carbonate/Text-Analysis-master/data/shakespearFolger'. While it might seem simpler to just save the whole file path as a variable and be done, however, this method allows for other users to utilize the code with minimal adjustments. \n",
    "\n",
    "The third variable, `textFile`, is the file of interest, in this case Hamlet, by William Shakespeare. \n",
    "\n",
    "The fourth variable uses the `PlaintextCorpusReader` function we pulled from nltk.corpus to read the file. This function can break text down into paragraphs, sentences (not lines), and words. Here we create the variable `corpus` which takes Hamlet and converts it from a 'str' class object into a 'nltk.corpus.reader.plaintext.PlaintextCorpusReader' class object so that the other functions built to work with this class of object will do what we want them to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "homePath = os.environ['HOME']\n",
    "\n",
    "corpusRoot = os.path.join(homePath, 'Text-Analysis-master','data','shakespeareFolger')\n",
    "\n",
    "textFile = 'Hamlet.txt'\n",
    "\n",
    "corpus = PlaintextCorpusReader(corpusRoot, textFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Class\n",
    "Sometimes you will get an error in Python that says that the function or action you are trying to use does not work with the type or 'class' of object you are trying to perform the action on. The next code basically says show (`print`) what class of object (`type`) my data or object is (`textFile`). In this case when we run the Python code, we see it is a string or 'str' object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(textFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we want to see what class it is after our reader function is finished with it, we simply change the object of interest in the parantheses to match. Since the `corpus` variable now refers to the resulting object after running our data through the PlaintextCorpusReader (from here on refered to as PCR) function, we will change `textFile` to `corpus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.plaintext.PlaintextCorpusReader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Inspection\n",
    "##### Paragraphs\n",
    "The PCR counts paragraphs by assuming that whitespace separates the paragraphs. Whitespace is generally anything that is 2 empty spaces or more. The first line of code takes the `corpus` variable we made before and applies the function of the PCR tool that separates the text into paragraphs by appending it to the end of the variable (`corpus.paras`) and calling the function but with no parameters (the empty parantheses) and saving it as a new variable called `paragraphs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paragraphs = corpus.paras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's say you want to count the number of paragraphs in the play Hamlet. You could simply put `print(len(paragraphs)`, which basically means show me (`print`) the number or length (`len`) of the variable `paragraphs`. As you can see, you get 450 paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450\n"
     ]
    }
   ],
   "source": [
    "print(len(paragraphs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are writing code using an IDE like Spyder or PyCharm, and your code is fairly complicated and gives you multiple results, it might be helpful to label those results or your 450 paragraphs could get lost in the shuffle. To print a label to go with your results you simply put the label in quotes. Python reads anything in quotes as a string, so if you give the command to print and have a phrase in quotes it will print that phrase. So the code below says to `print` the phrase `# of paragraphs:`. The `{}\\n` says put the results in place of the `{}`, then add a blank line (this is the `\\n` part). Make sure the `{}\\n` are inside the quotes too and you leave a space between the `:` and the `{}` or the answer will be placed right up against the colon. Then we tell Python the result to put in place of the `{}` using `.format` is the `len` (length) of the variable `paragraphs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of paragraphs: 450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('# of paragraphs: {}\\n'.format(len(paragraphs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the number of paragraphs is well and good, but you might want to see some of the paragraphs so you know what your code is actually counting as a paragraph. First, we choose a variable and make it equal to the number of paragraphs we wish to see. The reason we turn our number into a variable is because this number is important to a couple different parts of our code and this way if we wish to change the number of paragraphs we want to see, we only have to change the number in this variable. This eliminates the potential for error as we don't have to go through and change the number in multiple places. Let's start with a paragraph count of 3. We name the variable `cnt`, so anytime you see `cnt` it actually is assigned to the number 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnt = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to print 3 paragraphs. First we set up our label. Notice the `{}` is in the middle of our phrase this time. That means the result will be placed there. In this case our result is simply whatever our 'cnt' variable is. This way, when we change `cnt`, our label automatically updates. Try playing with the `cnt` number and watch the label change from 'First 3 paragraphs:' to 'First 5 paragraphs:' and back again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 paragraphs:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('First {} paragraphs:\\n'.format(cnt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to print the actual paragraphs. To do this we create a `for` loop. The code below says for each individual paragraph ,`p`, in our `paragraphs` variable between the first paragraph and whatever our `cnt` variable is, `[0 : cnt]`, print that paragraph, `print(p)`, and then print a blank line, `print()`. Note that the first paragraph is numbered `0` and not `1`. Most programming languages start counting at '0' and Python is no different. Also, the letter you use does not have to be `p`. We use that simply because it makes sense when we as humans read the code. You could use z if you like, it would not matter. Just make sure the letter in the `for` loop matches the letter in the first print command. Also, indentation is important in Python. When you indent it says that the indent code belongs to the code that is not indented or is less indented above it. In our code the `print(p)` and `print()` are part of the `for` loop above them. In addition, the `:` after `[0 : cnt]:` closes our for loop and also says that there should be indented code following containing the statements to be executed in our loop. If you don't indent properly, you will often get an invalid syntax error. Now, let's run the whole code with the label and everything and see our results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 paragraphs:\n",
      "\n",
      "[['Who', \"'\", 's', 'there', '?']]\n",
      "\n",
      "[['Nay', ',', 'answer', 'me', '.'], ['Stand', 'and', 'unfold', 'yourself', '.'], ['Long', 'live', 'the', 'King', '!'], ['Barnardo', '.'], ['He', '.']]\n",
      "\n",
      "[['You', 'come', 'most', 'carefully', 'upon', 'your', 'hour', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('First {} paragraphs:\\n'.format(cnt))\n",
    "for p in paragraphs[0 : cnt]:\n",
    "    \n",
    "    print(p)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lines\n",
    "We are going to take a break from the PCR tool, but don't worry, we'll come back to it.\n",
    "\n",
    "If you are interested in the number of lines in your text, the PCR tool does not separate lines. This is most likely because Python does this all on it's own, no packages required. \n",
    "\n",
    "First, we are going to open our file, in this case it is once again Hamlet, but we are going to tell Python to open the file and refer to the file as `file`. By using a `with` statement at the beginning we are telling Python to close the file when we are done without having to type anything. The code says open the file ,`with open(os.path.join('path','to','your','file.txt'))`, and refer to the now opened file as `file` or whatever you want to call the file. The `:` at the end says that we are going to be doing more with this file.\n",
    "\n",
    "Now, we want Python to convert `file` into a list of lines. So we create the variable 'lines' and make it equal to this process. The code says to take `file` and convert the lines to a list ,`.readlines`, and now execute this function (the empty parantheses). \n",
    "\n",
    "Now we have a list of lines, including blank ones, and at the moment it will count those empty lines since they contain the '\\n' which signifies a 'new line' and is what `readlines` is actually using to determine what a line is. So we create another variable called `linesRd` and make it equal to the result of the script that follows. That script basically says go through every line ,`line for line`, in the variable `lines` and only keep the line if when you strip the '\\n' from an individual line,`if l.strip('\\n')`, it does not equal nothing ,`!= ''`, or only keep the lines that have stuff in them when you remove the '\\n'. Now we have a list of lines that all contain text with no blank lines.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open (os.path.join(corpusRoot, 'Hamlet.txt')) as file:\n",
    "    lines = file.readlines()\n",
    "    linesRd = [line for line in lines if line.strip('\\n') != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we print out the number of total lines, as well as the text of the first 5 lines and the last 5 lines. This all works the same as when we counted the paragraphs above and text of the first 3 paragraphs, with the exception of counting the last 5 lines. For that, the code looks almost identical to what we do to count the first 5 lines, except in the `For` statement. The part where we say which lines we want to see for the first 5 lines:`linesRd[0 : lncnt]`, looks like this for the last 5 lines: `linesRd[-lncnt:]`. We are saying we want to start our count at the opposite end and go until you come to the end. If you know how many lines you have total, you could also put the number of the last 5 lines, which in our case is [4149 : 4154]. However, the code below will give you the last lines without having to have an exact count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of lines: 4154\n",
      "\n",
      "First 5 lines:\n",
      "\n",
      " Who's there?\n",
      "\n",
      "\n",
      " Nay, answer me. Stand and unfold yourself.\n",
      "\n",
      "\n",
      " Long live the King!\n",
      "\n",
      "\n",
      " Barnardo.\n",
      "\n",
      "\n",
      " He.\n",
      "\n",
      "\n",
      "Last 5 lines:\n",
      "\n",
      " The soldier's music and the rite of war\n",
      "\n",
      "\n",
      " Speak loudly for him.\n",
      "\n",
      "\n",
      " Take up the bodies. Such a sight as this\n",
      "\n",
      "\n",
      " Becomes the field but here shows much amiss.\n",
      "\n",
      "\n",
      " Go, bid the soldiers shoot.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lncnt = 5\n",
    "print('# of lines: {}\\n'.format(len(linesRd)))\n",
    "     \n",
    "print('First {} lines:\\n'.format(lncnt))\n",
    "for l in linesRd[0 : lncnt]:\n",
    "    print(l)\n",
    "    print()\n",
    "    \n",
    "print('Last {} lines:\\n'.format(lncnt))\n",
    "for l in linesRd[-lncnt:]:\n",
    "    print(l)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sentences\n",
    "Now we come back to our PCR tool. The PCR tool can also separate the text into sentences, but uses punctuation to do so. This means it will not work if you have removed punctuation before attempting this. This is also different from counting lines as the lines use '\\n' to determine what a line is, while the PCR sentence function uses '.', '?', and '!' to separate out sentences. For this we have also added code that shows the last 5 sentences. To practice, try adjusting the code so you can add it to the paragraphs section above and see the last paragraphs of Hamlet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sentences: 2494\n",
      "\n",
      "First 5 sentences:\n",
      "\n",
      "['Who', \"'\", 's', 'there', '?']\n",
      "\n",
      "['Nay', ',', 'answer', 'me', '.']\n",
      "\n",
      "['Stand', 'and', 'unfold', 'yourself', '.']\n",
      "\n",
      "['Long', 'live', 'the', 'King', '!']\n",
      "\n",
      "['Barnardo', '.']\n",
      "\n",
      "Last 5 sentences:\n",
      "\n",
      "['But', 'let', 'this', 'same', 'be', 'presently', 'performed', 'Even', 'while', 'men', \"'\", 's', 'minds', 'are', 'wild', ',', 'lest', 'more', 'mischance', 'On', 'plots', 'and', 'errors', 'happen', '.']\n",
      "\n",
      "['Let', 'four', 'captains', 'Bear', 'Hamlet', 'like', 'a', 'soldier', 'to', 'the', 'stage', ',', 'For', 'he', 'was', 'likely', ',', 'had', 'he', 'been', 'put', 'on', ',', 'To', 'have', 'proved', 'most', 'royal', ';', 'and', 'for', 'his', 'passage', ',', 'The', 'soldier', \"'\", 's', 'music', 'and', 'the', 'rite', 'of', 'war', 'Speak', 'loudly', 'for', 'him', '.']\n",
      "\n",
      "['Take', 'up', 'the', 'bodies', '.']\n",
      "\n",
      "['Such', 'a', 'sight', 'as', 'this', 'Becomes', 'the', 'field', 'but', 'here', 'shows', 'much', 'amiss', '.']\n",
      "\n",
      "['Go', ',', 'bid', 'the', 'soldiers', 'shoot', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = corpus.sents()\n",
    "\n",
    "print('# of sentences: {}\\n'.format(len(sentences)))\n",
    "\n",
    "sntcnt = 5\n",
    "\n",
    "print('First {} sentences:\\n'.format(sntcnt))\n",
    "\n",
    "for s in sentences[0 : sntcnt]:\n",
    "    \n",
    "    print(s)\n",
    "    print()\n",
    "\n",
    "print('Last {} sentences:\\n'.format(sntcnt))\n",
    "\n",
    "for s in sentences[-sntcnt:]:\n",
    "    \n",
    "    print(s)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Words\n",
    "Finally, we want to count words and perhaps see the first 10 words in our text. If you use PCR it will include punctuation as a seperate 'word' or 'token' and include it in the count as well as show each apostrophe and comma as a separate word. This can definitely be useful and the code is the same as with the paragraphs and sentences sections above, only the initial function and variables are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of tokens: 36653\n",
      "\n",
      "First 10 tokens:\n",
      "\n",
      "Who\n",
      "\n",
      "'\n",
      "\n",
      "s\n",
      "\n",
      "there\n",
      "\n",
      "?\n",
      "\n",
      "Nay\n",
      "\n",
      ",\n",
      "\n",
      "answer\n",
      "\n",
      "me\n",
      "\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = corpus.words()\n",
    "\n",
    "print('# of tokens: {}\\n'.format(len(tokens)))\n",
    "\n",
    "tokcnt = 10\n",
    "\n",
    "print('First {} tokens:\\n'.format(tokcnt))\n",
    "\n",
    "for t in tokens[0 : tokcnt]:\n",
    "    \n",
    "    print(t)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to count and also see only words, with no punctuation, then PCR is not a good option, however, this is once again because Python has a way of doing this all on it's own with a built in package called 'string'. So we `import string`. \n",
    "\n",
    "Next we need to create a statement. We assign the statement to the variable `remove` and the statement is as follows: create a blank dictionary using what is coming next, `dict.fromkeys`, then we use the `map` function which allows us to apply a given function to a list of iterables or tuples. Meaning we can apply a function to everything that comes after without having to apply the function to each item individually. Here we apply the function `ord` to everything that comes next. The `ord` function converts non-unicode characters to the unicode equivalent. We are applying this to the `string.punctuation` item and putting all the characters in `string.punctuation` into the dictionary and refering to this whole process as `remove`.\n",
    "\n",
    "Then we open the file like we did in the lines section above. We then read the file, `ham.read()`, while using the `remove` dictionary we made for the translate function, `translate(remove)`, which removes anything found in the dictionary, and then we apply the `split` function which separates or \"splits\" the document into a list of words. We name the result of this process `wrds`. The rest is the same as the other sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of words: 29648\n",
      "\n",
      "First 10 words:\n",
      "\n",
      "Whos\n",
      "\n",
      "there\n",
      "\n",
      "Nay\n",
      "\n",
      "answer\n",
      "\n",
      "me\n",
      "\n",
      "Stand\n",
      "\n",
      "and\n",
      "\n",
      "unfold\n",
      "\n",
      "yourself\n",
      "\n",
      "Long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "remove = dict.fromkeys(map(ord, string.punctuation))\n",
    "\n",
    "with open (os.path.join(corpusRoot, 'Hamlet.txt')) as ham:\n",
    "    wrds = ham.read().translate(remove).split()\n",
    "    \n",
    "\n",
    "print('# of words: {}\\n'.format(len(wrds)))\n",
    "\n",
    "wrdcnt = 10\n",
    "\n",
    "print('First {} words:\\n'.format(wrdcnt))\n",
    "\n",
    "for w in wrds[0 : wrdcnt]:\n",
    "    \n",
    "    print(w)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore\n",
    "The above commands are a few tips and tricks to get you started with Python. Similar to Python's extensibility with packages, the Python user community has great resouces for learners. The [Python Package Index](https://pypi.python.org/pypi) and the [Python Docs](https://docs.python.org/3/contents.html) answer quite a few questions about Python and its uses.\n",
    "\n",
    "Googling the issue, function, package, or object name with \"python\" will return helpful resources. If a website dedicated to the specific package appears, there you will find extensive documentation and examples for the package's functions, etc. and other related resources. For any other issues, Stack Overflow is helpful to find answers to common questions as well as ask your own.\n",
    "\n",
    "The rest of the IU Cyber DH tutorials explain some methods for textual analysis using Python. If you are ready to dive in, click on one to begin!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
